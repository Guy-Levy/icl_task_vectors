TASKS_TO_EVALUATE = [
    # One for each category
    # "translation_fr_en",
    # "linguistic_present_simple_gerund",
    # "knowledge_country_capital",
    # "algorithmic_next_letter",
    # # Translation
    # "translation_es_en",
    # "translation_en_fr",
    # "translation_en_es",
    # # Linguistic
    # "linguistic_present_simple_past_simple",
    # "linguistic_plural_singular",
    # "linguistic_antonyms",
    # # Knowledge
    # "knowledge_person_language",
    # "knowledge_location_continent",
    # "knowledge_location_religion",
    # # Algorithmic
    # "algorithmic_prev_letter",
    # "algorithmic_list_first",
    # "algorithmic_list_last",
    # "algorithmic_to_upper",
    # "algorithmic_to_lower",
    
    # Custom
    "next_letter",
    "prev_letter",
    "to_uppercase",
    "count_char_in_string",
    "abs_round",
    "array_average",
    "array_min",
    "array_sum",
    "division",
    "round",
    "string_to_mask_by_char",
    "string_to_mask_by_char2",
    "absolute",
    "array_length",
    "array_max",
    "subtraction",
    "array_max_diff",
    "first_letter",
    "first_letter_to_upper",
    "next_of_first_letter",
    "prev_of_first_letter",
    "city_PM",
    "city_country",
    "country_PM",
    "country_capital",
    "location_country",
    "city_PMbirthYear",
    "city_mayor",
    "country_capitalMayor",
    "location_capitalMayor",
    "person_birthYear",
    "adjective_superlative",
    "antonym_superlative",
    "antonyms",
    "past_oppositeGerund",
    "past_present",
    "present_gerund",
    "antoym_to_reversed",
    "en_es",
    "division_new_format",
    "reversed_words",
    "subtract_new_format",
    "word_length",
]

COMPLEX_TASKS_TO_EVALUATE = {
    "first_letter_to_upper",
    "next_of_first_letter",
    "prev_of_first_letter",
    "count_char_in_string",
    "abs_round",
}

MODELS_TO_EVALUATE = [
    # ("gpt-2", "1.5B"),
    # ("pythia", "2.8B"),
    # ("llama", "7B"),
    ("gpt-j", "6B"),
    ("pythia", "6.9B"),
    # ("llama", "13B"),
    ("pythia", "12B"),
    # ("llama", "30B"),
    # ("mpt", "7B"), # error in ForwardTracer
    # ("falcon", "7B"), # error in past_key_values
]
